{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48032b6f",
   "metadata": {},
   "source": [
    "### Translate\n",
    "    # addsub\n",
    "    # multiarith\n",
    "    # singleeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc4b4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import yaml\n",
    "from src import utils\n",
    "import time\n",
    "from pprint import pprint\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341f69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT = {\n",
    "#     '3p' : get_3p_prompt,\n",
    "#     'cot' : get_CoT_prompt,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784da61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = 'openai'\n",
    "api_key_file = '/userhomes/philhoon/kt-ai-challenge/api-openai.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da6c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name=\"gpt-3.5-turbo-0301\",\n",
    "model_name = \"gpt-3.5-turbo-0613\"\n",
    "\n",
    "max_token=2048\n",
    "temperature=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e752418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/userhomes/philhoon/kt-ai-challenge/eng_data/D_multiarith.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363d195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'kor-' + input_file.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd66a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/userhomes/philhoon/kt-ai-challenge/eng_data/kor-D_multiarith.json\n"
     ]
    }
   ],
   "source": [
    "output_path = '/userhomes/philhoon/kt-ai-challenge/eng_data'\n",
    "output_file = output_path + '/' + output_file_name\n",
    "print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7c2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai key\n",
    "key_dict = utils.get_keys(api_key_file)\n",
    "openai.api_key = key_dict[api]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e421b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = '/userhomes/philhoon/kt-ai-challenge/data/public_mwp_data_v2_reasoning.jsonl'\n",
    "# print(f'output_file : {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7283f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai-gpt-3.5-turbo-0301-2048-0.0-gsm8k-test.jsonl -> openai-gpt-3.5-turbo-0301-3p-2048-0.0-gsm8k-test.jsonl\n",
    "# openai-gpt-3.5-turbo-0301-gsm8k-test.jsonl -> openai-gpt-3.5-turbo-0301-3p-inf-1.0-gsm8k-test.jsonl\n",
    "# openai-gpt-3.5-turbo-0301-2048-0.0-gsm8k-test.jsonl -> openai-gpt-3.5-turbo-0301-3p-2048-0.0-gsm8k-test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2203391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = output_path + '/' + 'gsm8k-korean.jsonl'\n",
    "# print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd9e0984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jsonlines writier\n",
    "jsonl_writer = utils.JSONLWriter(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b79621",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.read_json_file(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ce2ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9caf98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63d5a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_line_split(context):\n",
    "    context = re.sub(r'\\n{1,}', ' ', context)\n",
    "    context = re.sub(r'\\s{2,}', ' ', context)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "938ac5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(message, model_name, max_token, temperature):\n",
    "    \"\"\"\n",
    "    Generate response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=model_name,\n",
    "            messages=message,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_token,\n",
    "            n=1)\n",
    "    except:\n",
    "        print(\"retrying due to an error......\")\n",
    "        time.sleep(20)\n",
    "        return generate_answer(message, model_name, max_token, temperature)\n",
    "\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48c213ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trans_msg(context):\n",
    "    \"\"\"\n",
    "    Message for chat api\n",
    "    \"\"\"\n",
    "\n",
    "    msg = [\n",
    "        {\n",
    "            \"role\" : \"system\",\n",
    "            \"content\" : \"Translate given setences into Korean.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : context\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3863723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b221b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                                                                                                                                    | 1/600 [00:09<1:32:48,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': '39',\n",
      " 'completion': ' 39.',\n",
      " 'completion_index': 0,\n",
      " 'kor_ans': '데비와 그녀의 여동생은 총 32 + 42 = 74개의 사탕을 가지고 있습니다. 그들은 35개를 먹었으므로, 남은 '\n",
      "            '사탕은 74 - 35 = 39개입니다.',\n",
      " 'kor_query': '할로윈에 데비와 그녀의 여동생은 받은 사탕을 합쳤습니다. 데비는 32개의 사탕을 가지고 있었고, 그녀의 여동생은 '\n",
      "              '42개를 가지고 있었습니다. 첫날 밤에 35개의 사탕을 먹었다면, 남은 사탕은 몇 개인가요?',\n",
      " 'prompt': 'Q: For Halloween Debby and her sister combined the candy they '\n",
      "           'received. Debby had 32 pieces of candy while her sister had 42. If '\n",
      "           'they ate 35 pieces the first night, how many pieces do they have '\n",
      "           'left?\\n'\n",
      "           \"A: Let's think step by step. \\n\"\n",
      "           '\\n'\n",
      "           'Debby and her sister have a total of 32 + 42 = 74 pieces of '\n",
      "           'candy.\\n'\n",
      "           'They eat 35 pieces, so they have 74 - 35 = 39 pieces left. '\n",
      "           'Therefore, the answer (arabic numerals) is',\n",
      " 'question': 'For Halloween Debby and her sister combined the candy they '\n",
      "             'received. Debby had 32 pieces of candy while her sister had 42. '\n",
      "             'If they ate 35 pieces the first night, how many pieces do they '\n",
      "             'have left?',\n",
      " 'reasoning_completion': ' \\n'\n",
      "                         '\\n'\n",
      "                         'Debby and her sister have a total of 32 + 42 = 74 '\n",
      "                         'pieces of candy.\\n'\n",
      "                         'They eat 35 pieces, so they have 74 - 35 = 39 pieces '\n",
      "                         'left.',\n",
      " 'reasoning_finish_reason': 'stop',\n",
      " 'reasoning_prompt': 'Q: For Halloween Debby and her sister combined the candy '\n",
      "                     'they received. Debby had 32 pieces of candy while her '\n",
      "                     'sister had 42. If they ate 35 pieces the first night, '\n",
      "                     'how many pieces do they have left?\\n'\n",
      "                     \"A: Let's think step by step.\",\n",
      " 'sample_index': 0}\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for ins in tqdm(data.values()):\n",
    "    instance = ins[0]\n",
    "\n",
    "#     pprint(cur_ins)\n",
    "    \n",
    "    eng_comp = remove_line_split(instance['reasoning_completion'])\n",
    "    eng_query = instance['question']\n",
    "    \n",
    "    query_msg = get_trans_msg(eng_query)\n",
    "    ans_msg = get_trans_msg(eng_comp)\n",
    "    \n",
    "    query_completion = generate_answer(query_msg, model_name, max_token, temperature)\n",
    "    q_response = query_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    ans_completion = generate_answer(ans_msg, model_name, max_token, temperature)\n",
    "    ans_response = ans_completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    instance['kor_query'] = q_response\n",
    "    instance['kor_ans'] = ans_response\n",
    "    pprint(instance)\n",
    "#     jsonl_writer.write_json_line(ins)a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce3d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-debate",
   "language": "python",
   "name": "self-debate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
